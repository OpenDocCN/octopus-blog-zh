# 安全模式更新-弹性与稳健的 IT 系统- Octopus 部署

> 原文：<https://octopus.com/blog/safe-schema-updates-2-resilience-vs-robustness>

这篇文章是我的安全模式更新系列的第 2 部分。

本系列其他文章的链接如下:

**批评现有系统:**

**想象更好的系统:**

**构建更好的系统:**

在第 1 部分中，我们回顾了与对数据库管理和设计的传统态度相关的常见的恶性循环。在接下来的几篇文章中，我们将探索一些重要的理论概念，这些概念有助于解释为什么最规避风险的组织通常会创建最危险的数据库。我们还会想象一个更安全的数据架构和开发文化会是什么样子。

在我们对为什么一些系统比其他系统更可靠有了更深的理解之后，我们将讨论团队可以做出的一些技术改变，这些改变应该导致显著更好的数据库可靠性和改进的业务成果，以及更人性化的工作条件。

在这篇文章中，我们回顾了软件系统中弹性和健壮性的概念。以下是我最喜欢的关于这种差异的简短表述:

“在过去的十年里，人们对构建具有三个特征的弹性系统进行了大量讨论:

*   低 MTTR *【平均恢复时间】*，这是因为对监控良好的故障场景进行了自动补救。
*   由于分布式和冗余环境，在故障期间影响较小。
*   将故障视为系统中正常情况的能力，确保自动和手动补救措施得到良好记录、扎实设计和实施，并集成到正常的日常操作中。

请注意，重点不在于消除故障。没有故障的系统虽然健壮，但也会变得脆弱。当故障发生时，更有可能的情况是响应团队毫无准备，这可能会极大地增加事故的影响。此外，可靠但脆弱的系统可能会导致用户期望比 SLO *【服务水平目标】*所指示的更高的可靠性，而这正是服务设计的目标。这意味着，即使没有违反 SLO，当停机发生时，客户也可能会非常不安。"

*来自[数据库可靠性工程](https://octopus.com/blog/devops-reading-list#dre)Laine Campbell 和 Charity Majors。*

我敢肯定，任何阅读本文的数据库管理员都会想到停机让一些利益相关者恼火的时候，即使从技术上讲，他们的 SLO 从未被违反。(假设他们首先有一个定义明确的 SLO。)

在深入研究坎贝尔和梅杰斯的评论之前，反思复杂系统中失败的本质是有价值的。为此，DevOps、 [Safety 2.0](https://www.england.nhs.uk/signuptosafety/wp-content/uploads/sites/16/2015/10/safety-1-safety-2-whte-papr.pdf) 、站点可靠性工程(SRE)和数据库可靠性工程(DRE)运动中的许多人参考了 Richard Cook 的简短学术著作: *[复杂系统如何失败](https://how.complexsystems.fail/)* 。

但在此之前，有必要区分真正“复杂”的系统和仅仅“复杂”的系统。

## 复杂系统与复杂系统

复杂的系统很难理解，但是只要有足够的努力和耐心，它们是可以理解的，结果是可以预测的。例如，加密算法很复杂。虽然我知道关于公钥加密如何工作的高级基础知识，但我不会假装熟悉具体的算法或它们的源代码。然而，我意识到，如果有足够的时间和技术能力，阅读文档并准确理解他们如何以可预测的方式加密和解密我们的数据是可能的。

复杂系统是不同的——它们是不可预测的。例如，预测天气就很复杂。我们可以进行各种测量，并将数字输入超级计算机，但即使有最精确的数据和算法，气象预测也永远不能保证。我们的测量和算法只是近似的，还有一些我们还没有完全理解的元素。因此，提前一个月准确预测天气实际上是不可能的。(尤其是我生活的地方——英国！)

根据定义，任何包含人类的系统都是复杂的，而不是复杂的。人类还没有创造出一个能够准确预测人类决策的系统。自由意志要么很难，要么不可能通过计算建模——我已经感觉自己掉进了一个哲学兔子洞。我的观点是，如果你的 it 系统依赖于人类来维护、更新或修复它，你的 IT 系统从定义上来说就是复杂的。这是因为人类是你系统的必要组成部分，人类是复杂的生物。

这还是在我们考虑在第 1 部分[中提到的许多缺乏文档记录或理解的依赖关系之前。任何没有 100%准确和最新文档的系统(根据定义)都是复杂的，因为不可能真正理解和预测单一变化的后果。由于我还没有遇到一个完整记录的大规模 IT 系统，我还没有看到一个可以被归类为复杂的，而不是复杂的。](https://octopus.com/blog/safe-schema-updates-1-delivery-hell)

## 理解复杂系统中失败的本质

希望标题*复杂系统如何失败*现在传达了一个更具体的想法。库克说的不是可预测的系统。根据定义，他说的是包含不可预测元素的系统，就像大多数(可能是所有)企业级 IT 系统一样。

也就是说，他主要写的是医院(他工作的地方)，以及其他高风险、复杂的环境，如航空业或军队。如果您是一名 IT 专业人员，认为失败的后果对您的 IT 系统影响很大，想象一下您是一名飞行员、伞兵或外科医生。

一个行动要成功，很多事情都要做好。手术室需要正确准备，所有必要的设备需要在正确的时间处于正确的位置，一群高素质的专业人员需要作为一个团队履行职责，以高标准，在紧张的条件下，经常解决意想不到的问题，并在进行中做出字面上的生死决定。

当事情进展不顺利时，我想“无可指责的验尸”这句话会让人感觉特别痛苦。我希望这是一个特别重要的实践。

虽然 it 故障很少导致生命损失，但任何有经验的 IT 专业人员都会阅读*复杂系统如何失败*，并本能地理解它适用于企业 IT，就像它适用于任何医院、客机或战舰一样。

*[复杂系统如何失败](https://how.complexsystems.fail/)* 大约是 10 分钟的阅读，在我看来，它应该是任何计算机科学学生或 it 专业人员的必读之作。在文章中，库克强调了成熟复杂系统中常见的 18 个具体的、可测量的属性:

1.  复杂系统本质上是危险系统。
2.  复杂系统成功地抵御了失败。
3.  灾难需要多次失败，单点失败是不够的。
4.  复杂的系统包含潜在的变化的故障组合。
5.  复杂系统以降级模式运行。
6.  灾难总是近在眼前。
7.  事故后归因于“根本原因”从根本上来说是错误的。
8.  事后诸葛亮会使事故后对人的表现的评估产生偏差。
9.  人类操作员有双重角色:生产者和防止失败的捍卫者。
10.  所有从业者的行为都是赌博。
11.  尖端的行动解决了所有的歧义。
12.  人类从业者是复杂系统中适应性强的元素。
13.  人类在复杂系统中的专业知识是不断变化的。
14.  变化带来了新形式的失败。
15.  对“原因”的看法限制了对未来事件防御的有效性。
16.  安全是系统的特性，而不是系统组件的特性。
17.  人们不断创造安全。
18.  无故障操作需要有失败经验。

请记住，这些是特指*不可预测的*复杂系统，比如假想的数据库及其来自[前一篇文章](https://octopus.com/blog/safe-schema-updates-1-delivery-hell)的依赖项。

深呼吸，然后再读一遍那张单子。这些观察对接下来的事情很重要。

我不打算为这些说法辩护或辩解。我也不打算在这方面做更多的阐述——库克自己做得很好，我不会因为重复这个练习而增加太多价值。我会接受它们，并假设它们是真的。如果你还没有准备好迈出这一步，我建议你在继续之前先完整阅读一下 *[复杂系统如何失败](https://how.complexsystems.fail/)* 。

接下来的讨论是关于我们如何能够并且应该对这些关于我们的 IT 系统中故障的本质的观察做出反应。

## 为什么弹性 IT 系统比强健的 IT 系统更安全

DevOps 运动通常被认为是 20 世纪 70 年代和 80 年代日本汽车制造业产生的精益思想的演变。然而，可以说，尤其是在最近几年，DevOps 将同样多的遗产归功于由库克及其同时代人开创的安全 2.0 运动。

与汽车制造和供应链管理不同，安全 2.0 是在 20 世纪 90 年代和 21 世纪初在医疗保健领域开发的。安全 2.0 是一种管理哲学，旨在培养库克在*复杂系统如何失败*中描述的各种复杂系统中的“安全文化”。

是时候给出另一个定义了，这个定义无耻地抄袭了其他人的优秀作品:

大多数人认为安全是指没有事故和事件(或可接受的风险水平)。从这个角度来看，我们称之为安全-I，安全被定义为一种尽可能少出错的状态。“安全第一”的方法假设事情出错是因为特定组件的可识别的故障或失灵:技术、程序、人类工人以及他们所在的组织。因此，人类——单独或集体行动——主要被视为一种责任或危险，主要是因为他们是这些因素中最易变的。Safety-I 中事故调查的目的是确定不良后果的原因和促成因素，而风险评估的目的是确定其可能性。安全管理的原则是当某件事情发生或被归类为不可接受的风险时做出反应，通常通过试图消除原因或改善障碍，或两者兼而有之。

[...]

至关重要的是，安全第一的观点并没有停下来考虑为什么人类的表现几乎总是正确的。事情不顺利，不是因为人们按照他们应该做的去做，而是因为人们能够并且确实调整他们的行为来适应工作环境。随着系统不断发展并引入更多的复杂性，这些调整对于保持可接受的性能变得越来越重要。因此，安全改进的挑战是理解这些调整——换句话说，理解尽管不确定性、模糊性和目标冲突在复杂的工作环境中普遍存在，但绩效通常是如何进行的。尽管事情进展顺利非常重要，但传统的安全管理很少关注这一点。

因此，安全管理应从确保“尽可能少的事情出错”转向确保“尽可能多的事情做对”。我们称这种观点为安全 II；它关系到系统在不同条件下成功的能力。Safety-II 方法假设日常表现的可变性提供了对变化的条件作出反应所需的适应性，因此是事情顺利进行的原因。因此，人被视为系统灵活性和复原力所必需的资源。在 Safety-II 中，调查的目的变成了理解事情通常是如何变好的，因为这是解释事情偶尔变坏的基础。风险评估试图了解绩效可变性变得难以或无法监控的情况。安全管理原则是促进日常工作，预测发展和事件，并保持适应能力，以有效应对不可避免的意外(Finkel 2011)。

霍尔内格尔 e，戴斯 R.L .和布莱斯维特 j.《从安全-I 到安全-II:白皮书》。弹性医疗保健网:由南丹麦大学、美国佛罗里达大学和澳大利亚麦考瑞大学同时出版。[此处可在线获得。](https://www.england.nhs.uk/signuptosafety/wp-content/uploads/sites/16/2015/10/safety-1-safety-2-whte-papr.pdf)

我从中得到的最大教训是，安全是你积极构建和完善的东西，而不是捕捉错误的看门人。增加创造安全的系统比试图抓住所有的错误更健康。毕竟，如果有足够的时间，期望你能抓住所有问题是不切实际的。

## 弹性 IT 系统的真实例子

实际上，那看起来像什么？嗯，它可能看起来像很多东西。网飞经常被描绘成 IT 弹性工程的典型代表，所以让我们来讨论一下他们是怎么做的。

2011 年 4 月 21 日， [AWS 在弗吉尼亚州(US-East-1)地区](https://aws.amazon.com/message/65648/)遭遇重大停电。这次故障导致许多主要网站瘫痪，包括 Reddit、Hootsuite、Quora 和 Windows 脸书应用。然而，网飞经受住了这场风暴。他们的用户几乎没有注意到。

之后，[网飞分享了一篇博客文章](https://netflixtechblog.com/lessons-netflix-learned-from-the-aws-outage-deefe5fd0c04)，解释了他们使用的一些技巧，这些技巧让他们在很多人失败的时候仍然在线。顺便说一句，2011 年并不是一次性的。网飞在 [2015](https://www.techrepublic.com/article/aws-outage-how-netflix-weathered-the-storm-by-preparing-for-the-worst/) 又做了一次，在 [2017](https://www.networkworld.com/article/3178076/why-netflix-didnt-sink-when-amazon-s3-went-down.html) 又做了一次。他们现在拥有在网络上生产最安全和最有弹性的系统的声誉。

为什么只有网飞能够在这场风暴中幸存下来？用他们自己的话来说(来自上面的博客)，他们的“系统是专门为这类故障设计的”。他们认识到库克教给我们的东西:复杂系统本质上是危险的系统，灾难总是迫在眉睫，他们在设计系统时考虑了这些事实。

他们的*系统对故障有很强的防御*，有许多聪明的自动故障转移和冗余特性。他们还明确设计了在降级模式下运行的方式。例如，他们认识到为用户提供推荐是有价值的，但不是必不可少的，他们意识到这在计算上是昂贵的。因此，当系统陷入困境时，他们可以自动关闭该功能(以及许多其他“值得拥有”的功能)，以保持核心运营在线。

从根本上来说，网飞以及任何其他弹性系统都认识到，在任何时候，它们都将包含潜在的各种不同的故障。他们认识到，所有的系统和依赖关系都可能在没有通知的情况下，以不可预测的方式发生故障，而不是仅仅设计专注于避免故障这一不可能任务的健壮系统。因此，最重要的是所有系统都被设计为保持在线，尽管可能处于降级模式，即使面对一个或多个故障，无论是内部基础设施/代码故障，还是依赖性。

此外，由于*无故障操作需要有故障经验*，因此有必要练习故障。而且有必要在不方便的时候练习。这就是为什么网飞故意随意破坏自己的服务。如果你从未听说过“混沌猴子”或“猿猴军”，你应该从创造它的人那里了解一下。

最后，正如 Cook 所明确指出的，操作员是系统不可分割的一部分。网飞的博客文章坚持软件的细节，但是人需要被重视，他们也需要被培训，保护和保持安全——就像系统的任何其他部分一样。

更重要的是，由于*人类从业者是复杂系统*的适应性元素，他们是投资的对象。最重要的是，我们明确认识到*所有从业者的行为都是赌博* , *事后对人的表现的事后评估存在偏见*，并且*事故后对“根本原因”的归因从根本上是错误的*。因此，在安全 IT 系统的开发中，指责和找特定个人的替罪羊是没有用的。如果人们犯了错误，他们会得到培训和支持，而不是绩效管理或遣散费。如果一个人会犯这个错误，其他人肯定会重复。与其试图将个人从系统中移除，不如将安全措施添加到系统中，以保护个人在未来不会重复类似的错误。毕竟，由于*无故障操作需要故障经验*，该个人可能已经学到了宝贵的经验，并且可能处于独特的位置，为这种测试/检查的发展做出贡献。

正如 IBM 首席执行官汤姆·沃森(1956-71)所言，当一位年轻的高管问他是否会因为一个代价高昂的错误而被解雇时:“完全不会，年轻人，我们刚刚花了几百万美元来教育你。”

## 实际上，这对我的数据库意味着什么？

首先，我们需要认识到*变化会带来新形式的失败*。这并不是说我们应该停止改变。如果有的话，我们应该更经常地做出改变！但是，我们应该设计我们的变更过程，以便尽可能有效地测试这些变更，并且当出现错误时，它们可以很容易地恢复。对于数据库来说，这是一项极具挑战性的任务，我们将在下一篇关于持续集成的文章中详细讨论，在本系列文章的末尾，我们将讨论配置环境和接近零停机时间部署的模式。

我们还应该设计有效的防火隔离带。一次错误的数据库更新不应该导致级联故障。需要控制故障，以便将其影响降至最低。这意味着我们需要避免单一的共享数据库，我们应该尝试将它们分割成能够独立运行的更小、更简单的系统，即使它们需要暂时以某种降级的能力运行。在后面关于松耦合和扼杀者模式的文章中，我们会更仔细地研究这个问题。

这些变化的结果应该是显著降低与任何数据库更新相关的风险。这种降低的风险应该减少对过度官僚化的变更管理过程的需求，允许更频繁地交付更小、更安全的更新，逆转上一篇文章中讨论的螺旋式下降，并导致一个持续改进的时期。

## 下次

在下一篇文章(第 3 部分)中，我们将讨论持续集成(CI)。具体来说，我们将讨论它是如何被误解的，误解可能造成的伤害，以及为任何 it 系统(包括任何关系数据库)采用“适当的”CI 的好处。

以下是本系列其他文章的链接。

**批评现有系统:**

**想象更好的系统:**

**打造更好的系统:**

## 观看网络研讨会

我们的第一次网络研讨会讨论了松耦合架构如何带来可维护性、创新性和安全性。第二部分讨论了如何将一个成熟的系统从一种架构转换到另一种架构。

### 数据库开发:想象更好的系统

[https://www.youtube.com/embed/oJAbUMZ6bQY](https://www.youtube.com/embed/oJAbUMZ6bQY)

VIDEO

### 数据库开发:构建更好的系统

[https://www.youtube.com/embed/joogIAcqMYo](https://www.youtube.com/embed/joogIAcqMYo)

VIDEO

愉快的部署！