<html>
<head>
<title>A look at the new NGINX VirtualServer and VirtualServerRoute resources - Octopus Deploy</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1>看看新的NGINX虚拟服务器和虚拟服务器路由资源——Octopus Deploy</h1>
<blockquote>原文：<a href="https://octopus.com/blog/nginx-ingress-crds#2021-08-12">https://octopus.com/blog/nginx-ingress-crds#2021-08-12</a></blockquote>
                        <p><a href="#" data-featherlight="https://i.octopus.com/blog/2020-02/nginx-ingress-crds/nginx-ingress-crds.png" class="zoom" data-title=""><img src="../Images/8d8622dee3ab55830b088c311f345c9b.png" class="img-fluid center" alt="NGINX VirtualServer and VirtualServerRoute resources" data-original-src="https://i.octopus.com/blog/2020-02/nginx-ingress-crds/nginx-ingress-crds.png"/>T2】</a></p>

<p>Kubernetes <code>Ingress</code>资源提供了一种配置传入HTTP流量的方式，并使得通过单个公共IP地址公开多个服务变得容易。</p>

<p>NGINX长期以来一直提供最受欢迎的入口控制器之一，但任何超过概念部署证明的东西都不可避免地意味着定制超越由<code>Ingress</code>资源公开的标准属性的路由规则。</p>

<p>直到最近，解决方案还是通过注释或在configmaps中提供配置块来定义这些附加设置。但是在1.5版本中，NGINX入口控制器提供了两个自定义资源定义(CRD)，定义了比基线<code>Ingress</code>资源更复杂的网络规则。</p>

<p>在本帖中，我们将探索由<code>VirtualServer</code>和<code>VirtualServerRoute</code>CRD提供的一些新功能。</p>

<h2 id="the-sample-kubernetes-cluster">Kubernetes星团样本</h2>

<p>对于这篇博客，我使用了与Docker桌面捆绑在一起的Kubernetes发行版:</p>

<p><a href="#" data-featherlight="https://i.octopus.com/blog/2020-02/nginx-ingress-crds/dockerdesktop.png" class="zoom" data-title=""><img src="../Images/58288ab9b09f2ae65d4d4ac28a66908b.png" class="img-fluid center" alt="" data-original-src="https://i.octopus.com/blog/2020-02/nginx-ingress-crds/dockerdesktop.png"/>T2】</a></p>

<p>然后，我部署了为<a href="https://octopus.com/blog/istio/the-sample-application"> Istio博客系列</a>创建的示例应用程序，它可以安装在:</p>

<pre><code>kubectl apply -f https://raw.githubusercontent.com/mcasperson/NodejsProxy/master/kubernetes/example.yaml
</code></pre>

<p>生成的群集如下所示:</p>

<p><a href="#" data-featherlight="https://i.octopus.com/blog/2020-02/nginx-ingress-crds/sampleapp.svg" class="zoom" data-title=""><img src="../Images/f3057f071a48a28f4750843e496bca93.png" class="img-fluid center" alt="" data-original-src="https://i.octopus.com/blog/2020-02/nginx-ingress-crds/sampleapp.svg"/>T2】</a></p>

<p>我用Helm安装了NGINX，但是并没有想象中那么容易。GitHub文档会把你带到https://helm.nginx.com/edge T2的Helm repo，这个对我来说是失败的。来自https://kubernetes-charts.storage.googleapis.com/<a href="https://kubernetes-charts.storage.googleapis.com/" rel="nofollow">官方舵手库的图表不包括CRDs。</a></p>

<p>解决方案是克隆NGINX Git repo并从本地文件安装Helm chart。这些命令适用于Helm 3:</p>

<pre><code>git clone https://github.com/nginxinc/kubernetes-ingress/
cd kubernetes-ingress/deployments/helm-chart
helm install nginx-release .
</code></pre>

<h2 id="a-basic-nginx-virtualserver">一个基本的NGINX虚拟服务器</h2>

<p>我们将从一个基本的<code>VirtualServer</code>资源开始来公开代理。</p>

<pre><code class="language-YAML">apiVersion: k8s.nginx.org/v1
kind: VirtualServer
metadata:
  name: virtualserver
spec:
  host: localhost
  upstreams:
  - name: proxy
    service: proxy
    port: 80
  routes:
  - path: /
    action:
      pass: proxy
</code></pre>

<p><code>upstreams</code>属性定义了流量可以发送到的服务。在这个例子中，我们将流量定向到<code>proxy</code>服务。</p>

<p><code>routes</code>匹配传入的请求并执行相应的动作。通常情况下，操作是将流量定向到上游服务器，我们已经用<code>action.pass: proxy</code>配置做到了这一点。</p>

<p>这个<code>VirtualServer</code>复制了我们在<code>Ingress</code>资源中定义的功能，一旦部署到集群，我们就可以打开http://localhost/whatever/you/want查看代理web应用程序。</p>

<h2 id="custom-actions">自定义操作</h2>

<p>当我们开始挖掘<code>VirtualServer</code>公开的新功能时，事情变得有趣了。</p>

<p><code>VirtualServer</code>可以将客户端重定向到一个新的URL，而不是将请求传递给上游服务。在这里，我们将流量引导回NGINX主页:</p>

<pre><code class="language-YAML">apiVersion: k8s.nginx.org/v1
kind: VirtualServer
metadata:
  name: virtualserver
spec:
  host: localhost
  routes:
  - path: /
    action:
      redirect:
        url: http://www.nginx.com
        code: 301
</code></pre>

<p>在这个例子中，我们定义了在<code>VirtualServer</code>资源中直接返回的内容。这对测试来说非常好:</p>

<pre><code class="language-YAML">apiVersion: k8s.nginx.org/v1
kind: VirtualServer
metadata:
  name: virtualserver
spec:
  host: localhost
  routes:
  - path: /
    action:
      return:
        code: 200
        type: text/plain
        body: "Hello World\n"
</code></pre>

<h2 id="traffic-splitting">流量分流</h2>

<p>通过将一定比例的流量定向到新服务，流量分割可用于canary部署。这里我们配置<code>VirtualServer</code>将流量传递给web服务器服务，在<code>webserverv1</code>和<code>webserverv2</code>之间分流流量。</p>

<pre><code class="language-YAML">apiVersion: k8s.nginx.org/v1
kind: VirtualServer
metadata:
  name: virtualserver
spec:
  host: localhost
  upstreams:
  - name: webserverv1
    service: webserverv1
    port: 80
  - name: webserverv2
    service: webserverv2
    port: 80
  routes:
  - path: /
    splits:
    - weight: 80
      action:
        pass: webserverv1
    - weight: 20
      action:
        pass: webserverv2
</code></pre>

<h2 id="load-balancing">负载平衡</h2>

<p>在<a href="https://kubernetes.io/docs/concepts/services-networking/service/#proxy-mode-iptables" rel="nofollow"> iptables代理模式</a>中，服务可用的端点是随机选择的。如果您查看上面的图表，<code>webserver</code>服务将流量同时定向到<code>webserverv1</code>和<code>webserverv2</code>部署，因此<code>webserver</code>服务的流量将在所有pod之间随机分配。</p>

<p>NGINX允许我们指定用于将流量导向上游服务的<a href="https://docs.nginx.com/nginx/admin-guide/load-balancer/http-load-balancer/#choosing-a-load-balancing-method" rel="nofollow">负载平衡规则</a>。在下面的例子中，我们将<code>lb-method</code>属性设置为<code>ip_hash</code>负载平衡算法，确保客户端总是被发送到同一个后端pod:</p>

<pre><code class="language-YAML">apiVersion: k8s.nginx.org/v1
kind: VirtualServer
metadata:
  name: virtualserver
spec:
  host: localhost
  upstreams:
  - name: webserver
    service: webserver
    port: 80
    lb-method: ip_hash
  routes:
  - path: /
    action:
      pass: webserver
</code></pre>

<h2 id="timeouts-retries-and-keepalives">超时、重试和保持活动</h2>

<p>连接超时、重试和保持活动等低级配置细节过去被定义为<code>Ingress</code>资源上的注释。有了<code>VirtualServer</code>资源，这些设置现在被公开为一级属性:</p>

<pre><code class="language-YAML">apiVersion: k8s.nginx.org/v1
kind: VirtualServer
metadata:
  name: virtualserver
spec:
  host: localhost
  upstreams:
  - name: webserver
    service: webserver
    port: 80
    fail-timeout: 10s
    max-fails: 1
    max-conns: 32
    keepalive: 32
    connect-timeout: 30s
    read-timeout: 30s
    send-timeout: 30s
    next-upstream: "error timeout non_idempotent"
    next-upstream-timeout: 5s
    next-upstream-tries: 10
    client-max-body-size: 2m
  routes:
  - path: /
    action:
      pass: webserver
</code></pre>

<h2 id="adding-virtualserverroutes">添加虚拟服务器路由</h2>

<p><code>VirtualServer</code>资源可以将请求委托给<code>VirtualServerRoute</code>。这允许主<code>VirtualServer</code>资源配置顶级流量规则，而<code>VirtualServerRoute</code>资源处理更具体的路由规则。</p>

<p>在下面的例子中，请求被发送到一个<code>VirtualServerRoute</code>资源，它根据路径从三个可能的上游服务中选择一个:</p>

<pre><code class="language-YAML">apiVersion: k8s.nginx.org/v1
kind: VirtualServer
metadata:
  name: virtualserver
spec:
  host: localhost
  routes:
  - path: /
    route: virtualserverroute
---
apiVersion: k8s.nginx.org/v1
kind: VirtualServerRoute
metadata:
  name: virtualserverroute
spec:
  host: localhost
  upstreams:
  - name: proxy
    service: proxy
    port: 80
  - name: webserverv1
    service: webserverv1
    port: 80
  - name: webserverv2
    service: webserverv2
    port: 80
  subroutes:
  - path: /webserverv1
    action:
      pass: webserverv1
  - path: /webserverv2
    action:
      pass: webserverv2
  - path: /
    action:
      pass: proxy
</code></pre>

<h2 id="conclusion">结论</h2>

<p>入口控制器最初是Kubernetes生态系统中的一个家庭手工业，但随着每个提供商通过新的配置选项和功能在竞争中脱颖而出，添加到<code>Ingress</code>资源的注释使它们变得笨重和不可移植。</p>

<p>通过实现CRDs，NGINX公开了具有可验证属性的高级功能。我希望这些CRD会随着更多的常见用例的确定而进一步丰富。</p>

                    
                    
</body>
</html>