<html>
<head>
<title>How to export metrics from Windows Kubernetes nodes in AKS - Octopus Deploy</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1>如何从AKS - Octopus Deploy中的Windows Kubernetes节点导出指标</h1>
<blockquote>原文：<a href="https://octopus.com/blog/export-metrics-from-windows-kubernetes-nodes-in-aks#2022-02-01">https://octopus.com/blog/export-metrics-from-windows-kubernetes-nodes-in-aks#2022-02-01</a></blockquote>
                        <p>在Octopus，我们使用Azure Kubernetes服务(<a href="https://azure.microsoft.com/en-au/services/kubernetes-service/" rel="nofollow"> AKS </a>)来管理一个<a href="https://kubernetes.io" rel="nofollow"> Kubernetes </a>集群，我们将其用于一系列内部工具，以及构建和测试工作负载。</p>

<p>为了有效地使用这种资源，我们需要监控它的使用量以及几个方面——CPU、内存、磁盘、网络带宽等等。</p>

<p>对于Linux <a href="https://kubernetes.io/docs/concepts/architecture/nodes/" rel="nofollow">节点</a>，我们使用<a href="https://github.com/SumoLogic/sumologic-kubernetes-collection" rel="nofollow"> Sumo Logic的解决方案从Kubernetes </a>收集指标，但它目前不支持从Windows收集指标。我们在集群中使用Windows节点，所以我们也需要一种方法来监控它们。</p>

<p>在本帖中，我将向你介绍我们的解决方案。如果您还需要Windows节点度量，我希望您可以使用这篇文章找到适合您的解决方案。</p>

<h2 id="gathering-metrics-on-windows-hosts">收集Windows主机上的指标</h2>

<p>收集关于Kubernetes (K8s)节点的指标对于Linux节点来说有一个既定的模式:</p>

<ul>
<li>在所有Linux节点上运行一组特权pods，并使用<a href="https://github.com/prometheus/node_exporter" rel="nofollow"> node_exporter </a>收集主机级指标</li>
<li>给它们贴上普罗米修斯能自动刮除的标签</li>
</ul>

<p>这在Windows上不起作用，因为Windows容器不能(<a href="https://github.com/Azure/AKS/issues/1975" rel="nofollow">目前是</a>)被赋予特权——这意味着它们不能看到主机VM的“外部世界”。所以我们需要其他方法来窥视宿主。</p>

<p>基于GitHub用户aidapsibr 的一个奇妙的<a href="https://github.com/aidapsibr/aks-prometheus-windows-exporter" rel="nofollow">解决方案，我们构建了一个非常接近Linux标准模式的方法。在我们的集群中工作的其他人现在可以理解监控管道是如何工作的，而不会有太多的困惑。</a></p>

<p>有三个组成部分:</p>

<ol>
<li>一个虚拟机规模集扩展，它在创建时在每个实例上安装<a href="https://github.com/prometheus-community/windows_exporter" rel="nofollow"> windows导出器</a> Windows服务</li>
<li>一个<a href="https://en.wikipedia.org/wiki/Reverse_proxy" rel="nofollow">反向代理</a>容器，用于将节点上运行的windows-exporter公开为集群中的服务</li>
<li>Prometheus将一些Windows指标转发到Sumo逻辑管道的两个远程写入规则</li>
</ol>

<h3 id="a-virtual-machine-scale-set-extension">虚拟机规模集扩展</h3>

<p>aidapsibr的解决方案使用PowerShell脚本安装该扩展一次，但是当我们使用Terraform和连续部署部署AKS集群时，我们需要一种方法来确保任何Windows节点池中的任何虚拟机最终都使用该扩展。幸运的是，<a href="https://registry.terraform.io/providers/hashicorp/azurerm/latest/docs/resources/virtual_machine_scale_set_extension" rel="nofollow">Azure provider for Terraform</a>已经有了一个scale set扩展资源，所以我们将下面的内容添加到我们的terra form文件中:</p>

<pre><code class="language-terraform">data "azurerm_virtual_machine_scale_set" "blue_bldwin" {
  depends_on = [
    azurerm_kubernetes_cluster_node_pool.blue_nautilus_buildwindows
  ]
  name                = "aksbldwin"
  resource_group_name = join("", ["MC_", var.environment, var.name, "_", var.environment, var.name, "aks_australiaeast"])
}
resource "azurerm_virtual_machine_scale_set_extension" "blue_windows_exporter" {
  depends_on = [
    data.azurerm_virtual_machine_scale_set.blue_bldwin
  ]
  name                         = "windows-exporter-dsc"
  virtual_machine_scale_set_id = data.azurerm_virtual_machine_scale_set.blue_bldwin.id
  publisher                    = "Microsoft.Powershell"
  type                         = "DSC"
  type_handler_version         = "2.80"
  # ensure that the AKS custom script extension has already run
  provision_after_extensions = ["vmssCSE"]
  auto_upgrade_minor_version = false
  settings = jsonencode({
    wmfVersion = "latest"
    configuration = {
      url      = var.vmss_metrics_extension_zip
      script   = "aks_setup"
      function = "Setup"
    }
    privacy = {
      dataEnabled = "Disable"
    }
  })
}
</code></pre>

<p>我们单独建立一个DSC。zip文件，上面引用为<code>var.vmss_metrics_extension_zip</code>，并将其作为GitHub发布工件托管。这个。zip文件包含windows-exporter。msi安装程序和PowerShell DSC模块文件，一旦VM启动并运行，扩展将调用该文件。该模块只安装。msi安装程序。</p>

<p>部署完成后，我们从集群内部手动抓取Windows节点，并获得普罗米修斯格式的指标:</p>

<pre><code># curl 10.240.0.4:9100/metrics | grep windows_cpu_time
# HELP windows_cpu_time_total Time that processor spent in different modes (idle, user, system, ...)
# TYPE windows_cpu_time_total counter
windows_cpu_time_total{core="0,0",mode="dpc"} 486.953125
windows_cpu_time_total{core="0,0",mode="idle"} 19035.953125
windows_cpu_time_total{core="0,0",mode="interrupt"} 18.53125
windows_cpu_time_total{core="0,0",mode="privileged"} 2327.78125
windows_cpu_time_total{core="0,0",mode="user"} 5324.1875
...
</code></pre>

<p>现在，我们需要一种方法来允许Kubernetes服务(和Prometheus ServiceMonitors)发现和收集这些指标——相当于用于Linux节点的DaemonSet。</p>

<h3 id="a-reverse-proxy">反向代理</h3>

<p>我们将nginx(一个广泛使用的<a href="https://en.wikipedia.org/wiki/Reverse_proxy" rel="nofollow">反向代理</a>)打包成一个容器，带有一个入口点，该入口点接收一个环境变量并将其用作这个配置文件中的上游服务器:</p>

<pre><code class="language-nginx">http {
    include       mime.types;
    default_type  application/octet-stream;
    sendfile        on;
    keepalive_timeout  65;
    upstream backendhostname {
            server PROXY_HOSTIP:PROXY_PORT;
    }
    server {
        listen       9100;
        server_name  localhost;
        location /health {
            return 200;
        }
        location /metrics {
            proxy_pass http://backendhostname/metrics;
            proxy_http_version 1.1; 
            proxy_set_header Upgrade $http_upgrade; 
            proxy_set_header Connection "upgrade"; 
        }
    }
}
</code></pre>

<p>通过将nginx容器部署为具有以下定义的DaemonSet，将<code>PROXYHOSTIP</code>设置为节点的内部IP:</p>

<pre><code class="language-yaml">apiVersion: apps/v1
kind: DaemonSet
metadata:
  name: # a useful name
  namespace: # your monitoring namespace
  labels:
    # labels that match any existing Prometheus ServiceMonitors
spec:
  selector:
    matchLabels:
      # labels that match any existing Prometheus ServiceMonitors
  updateStrategy:
    type: RollingUpdate
  template:
    metadata:
      labels:
        # labels that match any existing Prometheus ServiceMonitors
    spec:
      hostNetwork: false
      containers:
        - name: windows-metric-proxy
          image: # your docker container location
          imagePullPolicy: Always
          ports:
            - name: metrics
              containerPort: 9100
              protocol: TCP
          env:
            - name: PROXY_HOSTIP
              # this will get the current node's internal IP and forward metric scrapes to the windows-exporter service running on the node
              valueFrom:
                fieldRef:
                  fieldPath: status.hostIP
            - name: PROXY_PORT
              value: '9100'
      securityContext:
        runAsNonRoot: false
      nodeSelector:
        kubernetes.io/os: windows
</code></pre>

<p>如果您的标签与您现有的Linux节点度量管道的<code>ServiceMonitor</code>相匹配，Prometheus将自动挑选这些标签进行清理。对于相扑逻辑，这意味着:</p>

<pre><code class="language-yaml">labels:
  app: prometheus-node-exporter
  release: collection
</code></pre>

<p>现在，集群中的Prometheus实例正在收集指标，我们将它们发送到Sumo Logic进行长期保留。</p>

<h2 id="forwarding-to-sumo-logic">转发到相扑逻辑</h2>

<p>Sumo Logic收集解决方案是一个舵图，它安装了收集Kubernetes监控数据所需的一切(不仅仅是指标，还有事件、日志和各种各样的东西)。我们升级图表是我们持续部署集群基础架构的一部分。</p>

<p>该图表允许我们指定额外的远程写入规则，告诉Prometheus将指标发送到该图表也安装的fluentd实例——因此我们在我们的<code>values.yaml</code>覆盖文件中添加了两个规则，以将这些新的Windows指标发送到与Linux相同的位置。这是必要的，因为windows导出器不使用与Linux导出器相同的度量名称。</p>

<pre><code class="language-yaml">prometheus:
  prometheusSpec:
    nodeSelector:
      agentpool: default
    # Add new remote writes (toward fluentd) for our windows metrics, which are unfortunately prefixed with windows_
    # We don't need to use new fluentd targets because these represent the same measurements as the existing ones.
    remoteWrite:
      - url: http://$(FLUENTD_METRICS_SVC).$(NAMESPACE).svc.cluster.local:9888/prometheus.metrics.container
        remoteTimeout: 5s
        writeRelabelConfigs:
          - action: keep
            # regex: job-name;metric-name-regex
            regex: node-exporter;(?:windows_container_cpu_usage_seconds_total|windows_container_memory_working_set_bytes|windows_container_fs_usage_bytes|windows_container_fs_limit_bytes|windows_container_cpu_cfs_throttled_seconds_total|windows_container_network_receive_bytes_total|windows_container_network_transmit_bytes_total)
            sourceLabels: [job, __name__]
      - url: http://$(FLUENTD_METRICS_SVC).$(NAMESPACE).svc.cluster.local:9888/prometheus.metrics.node
        remoteTimeout: 5s
        writeRelabelConfigs:
          - action: keep
            regex: node-exporter;(?:windows_cpu_time_total|windows_logical_disk_free_bytes|windows_logical_disk_size_bytes|windows_memory_.*|windows_net_bytes_received_total|windows_net_bytes_sent_total|windows_os_.*|windows_system_.*)
            sourceLabels: [job, __name__]
</code></pre>

<p>注意:我们需要包含原始图表中所有其他的<code>remoteWrite</code>规则，因为如果我们只使用上面的值，它们就不再存在了。</p>


<h2 id="conclusion">结论</h2>

<p>连接上面的一切使我们能够在一个地方监视(例如)整个集群的节点磁盘消耗。这使得试验工作负载的变化变得非常容易，因为我们不再有耗尽集群资源的风险。</p>

<p><a href="#" data-featherlight="https://i.octopus.com/blog/2021-11/export-metrics-from-windows-kubernetes-nodes-in-aks/node-metrics-graph.png" class="zoom" data-title=""><img src="../Images/67b992bc100a6b61ecd06d3510f80a04.png" class="img-fluid center" alt="A screenshot of the Sumo Logic monitoring dashboard showing Windows and Linux disk metrics on one graph" data-original-src="https://i.octopus.com/blog/2021-11/export-metrics-from-windows-kubernetes-nodes-in-aks/node-metrics-graph.png"/></a>T2】</p>

<p>愉快的部署！</p>

<h2 id="learn-more">了解更多信息</h2>



                    
                    
</body>
</html>