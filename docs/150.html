<html>
<head>
<title>Custom kubectl scripting in Octopus - Octopus Deploy</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1>Octopus - Octopus Deploy中的自定义kubectl脚本</h1>
<blockquote>原文：<a href="https://octopus.com/blog/custom-kubectl-scripting-in-octopus#2021-08-12">https://octopus.com/blog/custom-kubectl-scripting-in-octopus#2021-08-12</a></blockquote>
                        <p><a href="#" data-featherlight="https://i.octopus.com/blog/2020-08/custom-kubectl-scripting-in-octopus/k8s-devops-runbook.png" class="zoom" data-title=""><img src="../Images/c8a75cafcdc9877b9c1813236d1486c6.png" class="img-fluid center" alt="Custom kubectl scripting in Octopus" data-original-src="https://i.octopus.com/blog/2020-08/custom-kubectl-scripting-in-octopus/k8s-devops-runbook.png"/>T2】</a></p>

<p>本系列之前的博客都关注于如何使用Octopus中固执己见的步骤来执行Kubernetes部署。但是有时候你需要直接进入脚本。也许你想利用定制的脚本工具，如<a href="https://istio.io/docs/ops/diagnostic-tools/istioctl/" rel="nofollow"> istioctl </a>或者使用Kubernetes资源提供的一些高级或不常见的属性。对于这些情况，Octopus允许您针对kubectl编写定制脚本。</p>

<p>在本帖中，我们将探讨一些技巧，您可以利用这些技巧来创建针对您的Kubernetes集群运行的灵活且可重用的脚本。</p>

<h2 id="create-a-kubectl-script">创建一个kubectl脚本</h2>

<p><strong>运行kubectl CLI脚本</strong>步骤展示了针对Kubernetes集群编写脚本的能力:</p>

<p><a href="#" data-featherlight="https://i.octopus.com/blog/2020-08/custom-kubectl-scripting-in-octopus/kubectl-step.png" class="zoom" data-title=""><img src="../Images/cdc408b63d39a85e651f23bd74dfe591.png" class="img-fluid center" alt="" data-original-src="https://i.octopus.com/blog/2020-08/custom-kubectl-scripting-in-octopus/kubectl-step.png"/>T2】</a></p>

<p>这一步类似于Octopus中的其他脚本步骤，只是它必须针对Kubernetes目标运行。在幕后，Octopus获取Kubernetes目标的细节，并构造一个配置文件，其作用范围是正在运行的脚本。它通过将环境变量<code>KUBECONFIG</code>设置为新生成的配置文件的路径来实现这一点，然后允许所有对<code>kubectl</code>的后续调用都指向Kubernetes目标。</p>

<p>下面是一个示例PowerShell脚本，它显示了环境变量和配置文件的内容:</p>

<pre><code class="language-powershell">echo "KUBECONFIG environment variable is set to: $($env:KUBECONFIG)"
echo "kubectl config view returns:"
kubectl config view
</code></pre>

<p>以下是结果截图:</p>

<p><a href="#" data-featherlight="https://i.octopus.com/blog/2020-08/custom-kubectl-scripting-in-octopus/script-output.png" class="zoom" data-title=""><img src="../Images/40036575b1199fcabb626bed1872da8f.png" class="img-fluid center" alt="" data-original-src="https://i.octopus.com/blog/2020-08/custom-kubectl-scripting-in-octopus/script-output.png"/>T2】</a></p>

<p>从输出中，我们可以看到Kubernetes配置文件已经保存到了<code>C:\Octopus\Master K8S Worker\Work\20200520001931-474360-35\kubectl-octo.yml</code>，这是一个临时目录，用来保存该步骤所需的工作文件。我们还可以看到配置文件是如何用保存在Kubernetes目标中的细节构建的。</p>

<h2 id="using-variables-in-scripts">在脚本中使用变量</h2>

<p>当该步骤运行时，我们的脚本可以访问所有可用的变量。查看可用变量的最简单方法是将<a href="https://octopus.com/docs/support/how-to-turn-on-variable-logging-and-export-the-task-log">章鱼变量</a> <code>OctopusPrintVariables</code>或<code>OctopusPrintEvaluatedVariables</code>设置为<code>True</code>:</p>

<p><a href="#" data-featherlight="https://i.octopus.com/blog/2020-08/custom-kubectl-scripting-in-octopus/debug-variables.png" class="zoom" data-title=""><img src="../Images/31e74e71be89e28fabf92dfa50568a87.png" class="img-fluid center" alt="" data-original-src="https://i.octopus.com/blog/2020-08/custom-kubectl-scripting-in-octopus/debug-variables.png"/>T2】</a></p>

<p>定义了这个变量后，详细日志将显示可用的变量及其值。这是浏览可在脚本中使用的变量的便捷方式:</p>

<p><a href="#" data-featherlight="https://i.octopus.com/blog/2020-08/custom-kubectl-scripting-in-octopus/variables-logs.png" class="zoom" data-title=""><img src="../Images/e30e7c4b086e181c628a04d2e3cd5cbc.png" class="img-fluid center" alt="" data-original-src="https://i.octopus.com/blog/2020-08/custom-kubectl-scripting-in-octopus/variables-logs.png"/>T2】</a></p>

<h2 id="referencing-docker-images">参考Docker图像</h2>

<p>Octopus部署过程的优点之一是部署逻辑是相对静态的，即使包每次都在变化。这是通过在部署时选择包来实现的。</p>

<p>然而，这个过程并不是Kubernetes所固有的。例如，在下面的部署YAML中，您可以看到我们已经硬编码了对Docker映像<code>mcasperson/mywebapp:0.1.7</code>的引用:</p>

<pre><code>apiVersion: apps/v1
kind: Deployment
metadata:
  name: mydeployment
  labels:
    app: mydeployment
spec:
  selector:
    matchLabels:
      app: mydeployment
  replicas: 1
  strategy:
    type: RollingUpdate
  template:
    metadata:
      labels:
        app: mydeployment
    spec:
      containers:
        - name: randomquotes
          image: mcasperson/mywebapp:0.1.7
          ports:
            - name: web
              containerPort: 80
</code></pre>

<p>即使我们没有提供标签并使用了一个图像引用<code>mcasperson/mywebapp</code>，标签<code>latest</code>也是假定的，所以我们仍然有效地拥有一个对单个Docker图像的硬编码引用。</p>

<p>为了让上面的YAML可以部署不同版本的Docker图像，我们可以使用Helm这样的工具通过模板定义图像标签。但是仍然需要有人知道Docker映像的版本并将其提供给Helm。</p>

<p>八达通提供了另一种选择。通过引用Docker映像作为附加包并将其设置为不被获取，Octopus将在部署期间提示选择映像的版本，然后在运行时将该版本作为变量公开。以下是作为附加包引用的Docker图像:</p>

<p><a href="#" data-featherlight="https://i.octopus.com/blog/2020-08/custom-kubectl-scripting-in-octopus/additional-package.png" class="zoom" data-title=""><img src="../Images/31e7e24ccce70e18a1d584a37c38fd2e.png" class="img-fluid center" alt="" data-original-src="https://i.octopus.com/blog/2020-08/custom-kubectl-scripting-in-octopus/additional-package.png"/>T2】</a></p>

<p>然后在部署期间选择包版本:</p>

<p><a href="#" data-featherlight="https://i.octopus.com/blog/2020-08/custom-kubectl-scripting-in-octopus/select-version.png" class="zoom" data-title=""><img src="../Images/9fdbee68366dc19f6799fadf7313ba50.png" class="img-fluid center" alt="" data-original-src="https://i.octopus.com/blog/2020-08/custom-kubectl-scripting-in-octopus/select-version.png"/>T2】</a></p>

<p>最后，我们扫描日志中打印的变量，找到引用Docker图像的变量。您可以在下面的截图中看到，名为<code>Octopus.Action.Package[mywebapp].Image</code>的变量是完整的Docker图像名称，<code>Octopus.Action.Package[mywebapp].PackageVersion</code>是版本:</p>

<p><a href="#" data-featherlight="https://i.octopus.com/blog/2020-08/custom-kubectl-scripting-in-octopus/image-variables.png" class="zoom" data-title=""><img src="../Images/5d2ede8d8fee8b32fdf0bec4efc9f682.png" class="img-fluid center" alt="" data-original-src="https://i.octopus.com/blog/2020-08/custom-kubectl-scripting-in-octopus/image-variables.png"/>T2】</a></p>

<p>我们可以在脚本中使用这些变量。下面的示例脚本将一个YAML文件写入磁盘，然后使用<code>kubectl</code>来应用它。image属性被定义为<code>image: #{Octopus.Action.Package[mywebapp].Image}</code>，它将在每次部署时更新，以反映所选的Docker映像:</p>

<pre><code class="language-Powershell">Set-Content -Path deployment.yml -Value @"
apiVersion: apps/v1
kind: Deployment
metadata:
  name: mydeployment
  labels:
    app: mydeployment
spec:
  selector:
    matchLabels:
      app: mydeployment
  replicas: 1
  strategy:
    type: RollingUpdate
  template:
    metadata:
      labels:
        app: mydeployment
    spec:
      containers:
        - name: randomquotes
          image: #{Octopus.Action.Package[mywebapp].Image}
          ports:
            - name: web
              containerPort: 80
"@

kubectl apply -f deployment.yml
</code></pre>

<h2 id="running-in-a-container-image">在容器映像中运行</h2>

<p>像Octopus这样的工具面临的一个挑战是它所集成的平台的数量，以及Octopus利用的工具。这个问题最初的解决方案是用Octopus本身打包工具，但是随着时间的推移，不同的工具版本、不同的操作系统以及新工具的不断引入使得这种方法无法维护。</p>

<p>这个问题的解决方案是引入<a href="https://hub.docker.com/r/octopusdeploy/worker-tools" rel="nofollow">工人工具Docker映像</a>，可以在其中执行部署流程。这些Docker映像包含了一些常见的开源工具，可以独立于Octopus本身进行版本控制和发布。</p>

<p>Octopus提供的图像包括Kubernetes工具的精选，包括<code>kubectl</code>、<code>istioctl</code>、<code>linkerd</code>和<code>helm</code>，这并不奇怪。</p>

<p>在下面的屏幕截图中，脚本步骤已被配置为在Worker tool Docker映像中运行:</p>

<p><a href="#" data-featherlight="https://i.octopus.com/blog/2020-08/custom-kubectl-scripting-in-octopus/worker-tools.png" class="zoom" data-title=""><img src="../Images/afd9eb8ac6902235443e1f3fecf18d3e.png" class="img-fluid center" alt="" data-original-src="https://i.octopus.com/blog/2020-08/custom-kubectl-scripting-in-octopus/worker-tools.png"/>T2】</a></p>

<p>但是，因为我们使用托管在Docker with Kind中的Kubernetes集群，所以我们必须做一些配置，以确保运行我们的Octopus步骤的Docker容器可以访问该集群。</p>

<p>首先，我们需要确保Kubernetes集群控制平面运行在名为<code>bridge</code>的默认Docker网络上。从<a href="https://github.com/kubernetes-sigs/kind/releases/tag/v0.8.0" rel="nofollow">版本0.8.0 </a>开始，Kind将在一个名为<code>kind</code>的特殊网络中创建Kubernetes集群，它将集群控制平面与运行我们部署的容器隔离开来。要解决这个问题，将<code>KIND_EXPERIMENTAL_DOCKER_NETWORK</code>环境变量设置为<code>bridge</code>，以强制Kind使用默认网络。</p>

<p>您可能需要用<code>kind cluster delete</code>删除现有的集群。然后按照<a href="/blog/getting-started-with-kind-and-octopus">上一篇博文</a>中的说明重新创建它，记住提取证书并重新上传到Octopus中，因为它们已经发生了变化。</p>

<p>我们还需要将我们的Kubernetes目标指向一个新的IP地址和端口。命令<code>docker container ls</code>向我们展示了托管Kubernetes控制平面的种类容器:</p>

<pre><code>$ docker container ls
CONTAINER ID        IMAGE                  COMMAND                  CREATED             STATUS              PORTS                       NAMES
ebb9eb784a55        kindest/node:v1.18.2   "/usr/local/bin/entr…"   6 minutes ago       Up 6 minutes        127.0.0.1:59747-&gt;6443/tcp   kind-control-plane
</code></pre>

<p>由此，我们可以看到端口<code>6443</code>是公开Kubernetes API的内部端口。</p>

<p>然后，我们用命令<code>docker container inspect kind-control-plane</code>获取容器的IP地址。以下是该命令输出的截断副本:</p>

<pre><code>$ docker container inspect kind-control-plane
[
    {
        // ... removed the container details for brevity
        "NetworkSettings": {
            // ... removed networking details for brevity
            "Networks": {
                "bridge": {
                    "IPAMConfig": null,
                    "Links": null,
                    "Aliases": null,
                    "NetworkID": "29f0f93df185df5ecae63abcca94c7a1bdd24a13bc8cd0158b2534199a08b95e",
                    "EndpointID": "0dc06d6e58a17e169d1c58a4ddaec179252d7b3e79695c40eba52af3ae8b921a",
                    "Gateway": "172.17.0.1",
                    "IPAddress": "172.17.0.2",
                    "IPPrefixLen": 16,
                    "IPv6Gateway": "",
                    "GlobalIPv6Address": "",
                    "GlobalIPv6PrefixLen": 0,
                    "MacAddress": "02:42:ac:11:00:02",
                    "DriverOpts": null
                }
            }
        }
    }
]
</code></pre>

<p>我们可以看到使用了<code>bridge</code>网络，这意味着<code>KIND_EXPERIMENTAL_DOCKER_NETWORK</code>环境变量按预期工作。然后我们看到<code>IPAddress</code>属性被设置为<code>172.17.0.2</code>。这意味着我们的Kubernetes集群的URL是<code>https://172.17.0.2:6443</code>:</p>

<p><a href="#" data-featherlight="https://i.octopus.com/blog/2020-08/custom-kubectl-scripting-in-octopus/internal-cluster.png" class="zoom" data-title=""><img src="../Images/61eb27eb1057a06613f36e97e564a9cd.png" class="img-fluid center" alt="" data-original-src="https://i.octopus.com/blog/2020-08/custom-kubectl-scripting-in-octopus/internal-cluster.png"/>T2】</a></p>

<p>既然我们已经为两个同级Docker容器配置了正确的网络来相互通信，我们可以通过运行脚本来验证worker-tools映像是否公开了我们期望的工具:</p>

<pre><code class="language-powershell">istioctl version
linkerd version
helm version
</code></pre>

<p>正如所料，我们的脚本可以使用所有这些工具:</p>

<p><a href="#" data-featherlight="https://i.octopus.com/blog/2020-08/custom-kubectl-scripting-in-octopus/script-result.png" class="zoom" data-title=""><img src="../Images/1cee4256c988026fe5d91a947fcecc4a.png" class="img-fluid center" alt="" data-original-src="https://i.octopus.com/blog/2020-08/custom-kubectl-scripting-in-octopus/script-result.png"/></a>T2】</p>

<h2 id="conclusion">结论</h2>

<p>通过暴露大量变量，允许在部署时选择Docker映像，并通过<a href="https://hub.docker.com/r/octopusdeploy/worker-tools" rel="nofollow">工人工具Docker映像</a>提供广泛的工具，可以从Octopus针对Kubernetes编写复杂的部署和管理任务。</p>

<p>这篇文章研究了Octopus中一些有用的调试技术，并提供了利用包变量和工人工具Docker images的示例脚本，以突出使用Octopus来自动化Kubernetes集群的一些可能性。</p>

                    
                    
</body>
</html>